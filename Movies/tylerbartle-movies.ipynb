{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CATEGORY_DFS = False\n",
    "KEEP_SETS = False\n",
    "DROPS = {'movie_name', 'description', 'director', 'star'}\n",
    "\n",
    "EXPLORE = False # Whether to execute the data exploration cells\n",
    "\n",
    "# NOTE: filters\n",
    "F_RUNTIME = (30, 300)\n",
    "F_YEAR = (1920, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Combining the CSVs as below is not used anymore, as the data is dealt with in DataFrames before concatenation.\n",
    "\"\"\"\n",
    "# Get all CSV file paths in the folder\n",
    "csv_files = glob.glob(os.path.join(\"Data\", '*.csv'))\n",
    "\n",
    "# Combine them\n",
    "combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# Save the result\n",
    "combined_df.to_csv('movies.csv', index=False)\n",
    "\n",
    "print(f\"Combined {len(csv_files)} files into 'movies.csv'.\")\n",
    "\"\"\"\n",
    "\n",
    "categories = {\n",
    "    'action',\n",
    "    'adventure',\n",
    "    'animation',\n",
    "    'biography',\n",
    "    'crime',\n",
    "    'family',\n",
    "    'fantasy',\n",
    "    'film_noir',\n",
    "    'history',\n",
    "    'horror',\n",
    "    'mystery',\n",
    "    'romance',\n",
    "    'scifi',\n",
    "    'sports',\n",
    "    'thriller',\n",
    "    'war'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Rather than defining each category DataFrame manually, the loop below defines them dynamically.\n",
    "\"\"\"\n",
    "action = pd.read_csv('Data/action.csv')\n",
    "adventure = pd.read_csv('Data/adventure.csv')\n",
    "animation = pd.read_csv('Data/animation.csv')\n",
    "biography = pd.read_csv('Data/biography.csv')\n",
    "crime = pd.read_csv('Data/crime.csv')\n",
    "family = pd.read_csv('Data/family.csv')\n",
    "fantasy = pd.read_csv('Data/fantasy.csv')\n",
    "film_noir = pd.read_csv('Data/film_noir.csv')\n",
    "history = pd.read_csv('Data/history.csv')\n",
    "horror = pd.read_csv('Data/horror.csv')\n",
    "mystery = pd.read_csv('Data/mystery.csv')\n",
    "romance = pd.read_csv('Data/romance.csv')\n",
    "scifi = pd.read_csv('Data/scifi.csv')\n",
    "sports = pd.read_csv('Data/sports.csv')\n",
    "thriller = pd.read_csv('Data/thriller.csv')\n",
    "war = pd.read_csv('Data/war.csv')\n",
    "\"\"\"\n",
    "\n",
    "for category in categories:\n",
    "    # Dynamically read each CSV file into a pd.DataFrame based on the category name\n",
    "        # and assign it to a global variable with the same name as the category\n",
    "    globals()[category] = pd.read_csv(f\"Data/{category}.csv\")\n",
    "\n",
    "del category\n",
    "\n",
    "# globals()['action'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_listlikes(df: pd.DataFrame, splits: Iterable, make_sets: bool) -> None:\n",
    "    \"\"\"\n",
    "    Cleans and splits specified columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df: The DataFrame to process.\n",
    "        splits: List of columns to split and clean.\n",
    "        make_sets: If `True`, creates a set of unique values for each column.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "\n",
    "    def split_multiples(df: pd.DataFrame, col: str) -> None:\n",
    "        \"\"\"\n",
    "        Splits the values in a column by `,` and stores them in a new column, as a list.\n",
    "\n",
    "        Parameters:\n",
    "            df: The DataFrame to process.\n",
    "            col: The column to split.\n",
    "        \n",
    "        Returns:\n",
    "            None: The function modifies the DataFrame in place.\n",
    "        \"\"\"\n",
    "\n",
    "        df[col + 's'] = \\\n",
    "            df[col].apply(\n",
    "                lambda x: {val.strip().lower() for val in x.split(',')}\n",
    "                    if pd.notnull(x) \n",
    "                    else None)\n",
    "        \n",
    "    def trim_name_urls(df: pd.DataFrame, col: str) -> None:\n",
    "        \"\"\"\n",
    "        Trims name URLs to just the important part.\n",
    "        This is used for director and star names.\n",
    "        \n",
    "        i.e. `'/name/nm0000001/'` becomes `'nm0000001'`\n",
    "        \n",
    "        Parameters:\n",
    "            df: The DataFrame to process.\n",
    "            col: The column to trim.\n",
    "        \n",
    "        Returns:\n",
    "            None: The function modifies the DataFrame in place.\n",
    "        \"\"\"\n",
    "\n",
    "        df[col] = df[col].apply(\n",
    "            lambda s: {x.split('/')[-2].strip() for x in s}\n",
    "                if isinstance(s, set) and len(s) > 0\n",
    "                else s)\n",
    "\n",
    "    if make_sets:\n",
    "        def track_uniques(df: pd.DataFrame, col: str, unique_set: set) -> None:\n",
    "            \n",
    "            \"\"\"\n",
    "            Tracks unique values in a column and stores them in a set.\n",
    "\n",
    "            Parameters:\n",
    "                df: The DataFrame to process.\n",
    "                col: The column to track unique values from.\n",
    "                unique_set: A set to store unique values.\n",
    "            \n",
    "            Returns:\n",
    "                None: The function modifies the set in place.\n",
    "            \"\"\"\n",
    "\n",
    "            for items in df[col + 's'].dropna():\n",
    "                # Add each item to the set\n",
    "                for item in items:\n",
    "                    unique_set.add(item)\n",
    "\n",
    "    ##########\n",
    "\n",
    "    for col in splits:\n",
    "        col_s = col + 's'\n",
    "        try:\n",
    "            # Split the column values by ',' and store in a new column\n",
    "            split_multiples(df, col)\n",
    "\n",
    "            # Trim name URLs for director and star names if applicable\n",
    "            if col_s in ['director_ids', 'star_ids']:\n",
    "                trim_name_urls(df, col_s)\n",
    "            elif col_s == 'genres':\n",
    "                # Convert genres to lowercase\n",
    "                g = {df['category'][0]}\n",
    "                df[col_s] = df[col_s].apply(lambda s: s | g)\n",
    "                df.drop(columns=['category'], inplace=True)\n",
    "\n",
    "            if make_sets:\n",
    "                # Track unique values for each column\n",
    "                globals()[col_s] = set()\n",
    "                track_uniques(df, col, globals()[col_s])\n",
    "\n",
    "            df.drop(columns=[col], inplace=True) # Drop the original column to save space\n",
    "        except KeyError:\n",
    "            # Handle the case where the column might not exist in the DataFrame (i.e. this function has already been performed)\n",
    "            print(f\"Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "            if make_sets:\n",
    "                # Initialize an empty set to avoid errors later on\n",
    "                if col_s not in globals():\n",
    "                    globals()[col_s] = set()\n",
    "\n",
    "def clean_runtime(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Cleans the runtime column in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df: The DataFrame to process.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert runtime to numeric values (in minutes)\n",
    "    df['runtime'] = df['runtime'].apply(\n",
    "        lambda x: int(x.split()[0].replace(',', '')) if pd.notnull(x) else None)\n",
    "\n",
    "def convert_year(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Converts the year column to numeric values.\n",
    "    \n",
    "    Parameters:\n",
    "        df: The DataFrame to process.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "    def _convert(x):\n",
    "        \"\"\"Helper function to convert year to int or None.\"\"\"\n",
    "        try:\n",
    "            return int(x)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "        \n",
    "    df['year'] = df['year'].apply(\n",
    "        lambda x: _convert(x) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(category: str, drops: Iterable = None, make_sets: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Performs all clean-up / preprocessing steps on the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df: The DataFrame to process.\n",
    "        drops: List of columns to drop from the DataFrame.\n",
    "        make_sets: If `True`, creates a set of unique values for each column.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "    df = globals()[category]\n",
    "\n",
    "    df['category'] = category\n",
    "    \n",
    "    df.dropna(inplace=True, how='all') # Drop rows where all elements are None\n",
    "    try:\n",
    "        df.drop(columns=drops, inplace=True) # Drop specified columns\n",
    "    except:\n",
    "        # Handle the case where the columns might not exist in the DataFrame\n",
    "        print(f\"Columns {drops} not found in DataFrame.\\nHas preprocessing already been performed?\")\n",
    "        return\n",
    "\n",
    "    # NOTE: splits is a list of columns to split by ','.\n",
    "        # 'director' and 'star' columns are likely not useful,\n",
    "        # as they are just text (meaningless to a model, likely),\n",
    "        # so if they are included in drops, they will be ignored here.\n",
    "    splits = {\n",
    "        'genre',\n",
    "        'director',\n",
    "        'director_id',\n",
    "        'star',\n",
    "        'star_id',\n",
    "    } - drops\n",
    "\n",
    "    split_listlikes(df, splits, make_sets)\n",
    "    clean_runtime(df)\n",
    "    convert_year(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    # Prepare each category DataFrame\n",
    "    prepare(category, drops=DROPS, make_sets=KEEP_SETS)\n",
    "\n",
    "del category\n",
    "\n",
    "# NOTE: now, each category's DataFrame has:\n",
    "# - Empty rows removed,\n",
    "# - useless columns dropped,\n",
    "# - list-like columns split into lists and the original columns removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: testing\n",
    "\n",
    "# type(globals()['action']['genres'][0])\n",
    "# print(globals()['genres'])\n",
    "# globals()['action']['certificate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DataFrames in categories into one DataFrame\n",
    "combined_df = pd.concat([globals()[category] for category in categories], ignore_index=True)\n",
    "# combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Exploring duplicate movie IDs\n",
    "\n",
    "# # Find movie_ids that are duplicated across all DataFrames\n",
    "# duplicated_ids = combined_df['movie_id'][combined_df['movie_id'].duplicated(keep=False)]\n",
    "\n",
    "# # Filter rows where movie_id is in the list of duplicated IDs\n",
    "# duplicates = combined_df[combined_df['movie_id'].isin(duplicated_ids)]\n",
    "# # duplicates.head()\n",
    "# duplicates[duplicates['movie_name'] == 'Black Panther: Wakanda Forever'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Minimizing bloat for testing aggregation\n",
    "# comb_example = combined_df[['movie_id', 'movie_name', 'genres']]\n",
    "# # comb_example.head()\n",
    "# dupl_example = duplicates[['movie_id', 'movie_name', 'genres']]\n",
    "# # dupl_example[dupl_example['movie_name'] == 'Black Panther: Wakanda Forever'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all rows with the same movie_id into a single row:\n",
    "# union all genre sets, and keep the first-appearing value for other columns.\n",
    "\n",
    "# Identify the columns other than movie_id and genre\n",
    "other_cols = [col for col in combined_df.columns if col not in ['movie_id', 'genres']]\n",
    "\n",
    "# Create an aggregation dictionary:\n",
    "#   - for all \"other\" columns, take 'first'\n",
    "#   - for 'genre', union the sets\n",
    "agg_dict = {col: 'first' for col in other_cols}\n",
    "agg_dict['genres'] = lambda genre_series: set().union(*genre_series)\n",
    "\n",
    "# Perform the groupby aggregation\n",
    "grouped_df = combined_df.groupby('movie_id', as_index=False).agg(agg_dict)\n",
    "\n",
    "# grouped_df.info()\n",
    "# grouped_df[grouped_df['movie_name'] == 'Black Panther: Wakanda Forever'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.info()\n",
    "# grouped_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is how many duplicate movie_ids were removed:\n",
    "# print(combined_df.shape[0] - grouped_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = grouped_df.copy()\n",
    "\n",
    "to_del = {'combined_df', 'duplicated_ids', 'duplicates', 'comb_example', 'dupl_example', 'other_cols', 'agg_dict', 'grouped_df'}\n",
    "if not KEEP_CATEGORY_DFS:\n",
    "    to_del |= categories\n",
    "\n",
    "for item in to_del:\n",
    "    try:\n",
    "        del globals()[item]\n",
    "    except KeyError:\n",
    "        pass\n",
    "del to_del\n",
    "del item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(id: str, type: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a link to the movie or person based on the ID and type.\n",
    "\n",
    "    Parameters:\n",
    "        id: The ID of the movie or person.\n",
    "        type: The type of the link (`'movie'` or `'person'`).\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted link.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.imdb.com\"\n",
    "    if   type == 'movie':\n",
    "        return f\"{base_url}/title/{id}/\"\n",
    "    elif type == 'person':\n",
    "        return f\"{base_url}/name/{id}/\"\n",
    "    else:\n",
    "        raise ValueError(\"Type must be either 'movie' or 'person'.\")\n",
    "    \n",
    "def show_sorted(df, cols: list, order_by: str, max: bool = True, n: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Sorts the DataFrame by a specified column and returns the top N rows.\n",
    "\n",
    "    Parameters:\n",
    "        df: The DataFrame to sort.\n",
    "        order_by: The column name to sort by.\n",
    "        ascending: If True, sorts in ascending order; otherwise, descending.\n",
    "        top_n: The number of top rows to return.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The sorted DataFrame with the top n rows.\n",
    "    \"\"\"\n",
    "    if order_by not in cols:\n",
    "        cols.append(order_by)\n",
    "    print(df.sort_values(by=order_by, ascending=not max).head(n)[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_link(movies['movie_id'][0], 'movie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_linked = movies.copy()\n",
    "movies_linked['movie_id'] = \\\n",
    "    movies_linked['movie_id'].apply(\n",
    "        lambda x: get_link(x, 'movie')\n",
    "            if pd.notnull(x)\n",
    "            else None)\n",
    "\n",
    "movies_linked['director_ids'] = \\\n",
    "    movies_linked['director_ids'].apply(\n",
    "        lambda ids: [get_link(id, 'person') for id in ids]\n",
    "            if isinstance(ids, set)\n",
    "            else None)\n",
    "\n",
    "movies_linked['star_ids'] = \\\n",
    "    movies_linked['star_ids'].apply(\n",
    "        lambda ids: [get_link(id, 'person') for id in ids]\n",
    "            if isinstance(ids, set)\n",
    "            else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(movies_linked.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runtime_histogram(df):\n",
    "    \"\"\"\n",
    "    Plots a vertical histogram of the 'runtime' column with a logarithmic x-axis.\n",
    "    Adds count labels on top of each bar.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing the 'runtime' column.\n",
    "        bins (int): Number of bins for the histogram.\n",
    "    \"\"\"\n",
    "    # Filter for valid runtime values\n",
    "    runtimes = df['runtime']\n",
    "    runtimes = runtimes[runtimes > 0]\n",
    "\n",
    "    bins = 30\n",
    "\n",
    "    # Set up logarithmic bins\n",
    "    log_bins = np.logspace(np.log10(runtimes.min()), np.log10(runtimes.max()), bins)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    counts, bins, patches = plt.hist(runtimes, bins=log_bins, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Add count labels on top of bars\n",
    "    for count, patch in zip(counts, patches):\n",
    "        if count > 0:\n",
    "            bar_center = patch.get_x() + patch.get_width() / 2\n",
    "            plt.text(bar_center, count + 0.5, f'{int(count)}', ha='center', va='bottom', fontsize=8, rotation=0)\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Runtime (log scale)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Runtimes')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    plot_runtime_histogram(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    show_sorted(movies_linked, ['movie_id', 'runtime', 'year'], 'runtime')\n",
    "# NOTE: the first one here, \"Ekalavya\", has a runtime of 138 minutes, not 5,538 (random +90h?); however, the others are accurate... lonk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    ml_f_runtime = movies_linked.copy()\n",
    "    ml_f_runtime = ml_f_runtime[(ml_f_runtime['runtime'] >= F_RUNTIME[0]) & (ml_f_runtime['runtime'] <= F_RUNTIME[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    plot_runtime_histogram(ml_f_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year_histogram(df):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the 'year' column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing the 'year' column.\n",
    "        bins (int): Number of bins to use in the histogram.\n",
    "    \"\"\"\n",
    "    years = df['year'].dropna()\n",
    "\n",
    "    year_range = years.max() - years.min()\n",
    "    bins = int(year_range / 4)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    counts, bins, patches = plt.hist(\n",
    "        years, bins=bins, align='left',\n",
    "        color='lightcoral', edgecolor='black'\n",
    "    )\n",
    "\n",
    "    # Add labels above bars\n",
    "    for count, patch in zip(counts, patches):\n",
    "        if count > 0:\n",
    "            plt.text(\n",
    "                patch.get_x() + patch.get_width() / 2,\n",
    "                count + 0.5,\n",
    "                str(int(count)),\n",
    "                ha='center', va='bottom', fontsize=8, rotation=0\n",
    "            )\n",
    "\n",
    "    plt.xlabel('Release Year')\n",
    "    plt.ylabel('Number of Movies')\n",
    "    plt.title('Histogram of Movie Release Years')\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    plot_year_histogram(movies_linked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    show_sorted(movies_linked, ['movie_id', 'year', 'runtime'], 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    ml_f_year = movies_linked.copy()\n",
    "    # ml_f_year = ml_f_year[(ml_f_year['year'] >= datetime.now().year)]\n",
    "    ml_f_year = ml_f_year[(ml_f_year['year'] >= F_YEAR[0]) & (ml_f_year['year'] <= F_YEAR[1])]\n",
    "    ml_f_year_new = ml_f_year[(ml_f_year['year'] >= F_YEAR[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    # ml_f_year.info()\n",
    "    ml_f_year_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    plot_year_histogram(ml_f_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Me the Numbahs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    # has_certificate = movies_linked.copy()\n",
    "    # has_certificate = has_certificate[has_certificate['certificate'].notnull()]\n",
    "\n",
    "    # has_votes = movies_linked.copy()\n",
    "    # has_votes = has_votes[has_votes['votes'].notnull()]\n",
    "\n",
    "    has_gross = movies_linked.copy()\n",
    "    has_gross = has_gross[has_gross['gross(in $)'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    # has_certificate.info()\n",
    "    # has_votes.info()\n",
    "    has_gross.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gross_pre2015 = has_gross.copy()\n",
    "# gross_pre2015 = gross_pre2015[gross_pre2015['year'] < 2015]\n",
    "\n",
    "# gross_post2015 = has_gross.copy()\n",
    "# gross_post2015 = gross_post2015[gross_post2015['year'] >= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gross_pre2015.info()\n",
    "# gross_post2015.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE:\n",
    "    plot_runtime_histogram(has_gross)\n",
    "    plot_year_histogram(has_gross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
