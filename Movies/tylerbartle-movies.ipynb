{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import numpy as np\n",
    "# import os\n",
    "import pandas as pd\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all CSV file paths in the folder\n",
    "# csv_files = glob.glob(os.path.join(\"Data\", '*.csv'))\n",
    "\n",
    "# # Combine them\n",
    "# combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# # Save the result\n",
    "# combined_df.to_csv('movies.csv', index=False)\n",
    "\n",
    "# print(f\"Combined {len(csv_files)} files into 'movies.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'action',\n",
    "    'adventure',\n",
    "    'animation',\n",
    "    'biography',\n",
    "    'crime',\n",
    "    'family',\n",
    "    'fantasy',\n",
    "    'film_noir',\n",
    "    'history',\n",
    "    'horror',\n",
    "    'mystery',\n",
    "    'romance',\n",
    "    'scifi',\n",
    "    'sports',\n",
    "    'thriller',\n",
    "    'war'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "action = pd.read_csv('Data/action.csv')\n",
    "adventure = pd.read_csv('Data/adventure.csv')\n",
    "animation = pd.read_csv('Data/animation.csv')\n",
    "biography = pd.read_csv('Data/biography.csv')\n",
    "crime = pd.read_csv('Data/crime.csv')\n",
    "family = pd.read_csv('Data/family.csv')\n",
    "fantasy = pd.read_csv('Data/fantasy.csv')\n",
    "film_noir = pd.read_csv('Data/film_noir.csv')\n",
    "history = pd.read_csv('Data/history.csv')\n",
    "horror = pd.read_csv('Data/horror.csv')\n",
    "mystery = pd.read_csv('Data/mystery.csv')\n",
    "romance = pd.read_csv('Data/romance.csv')\n",
    "scifi = pd.read_csv('Data/scifi.csv')\n",
    "sports = pd.read_csv('Data/sports.csv')\n",
    "thriller = pd.read_csv('Data/thriller.csv')\n",
    "war = pd.read_csv('Data/war.csv')\n",
    "'''\n",
    "\n",
    "for category in categories:\n",
    "    # Dynamically read each CSV file into a pd.DataFrame based on the category name\n",
    "        # and assign it to a global variable with the same name as the category\n",
    "    globals()[category] = pd.read_csv(f\"Data/{category}.csv\")\n",
    "\n",
    "del category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals()['action'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_columns(df: pd.DataFrame, splits: Iterable, make_sets: bool) -> None:\n",
    "    \"\"\"\n",
    "    Cleans and splits specified columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df: The DataFrame to process.\n",
    "        splits: List of columns to split and clean.\n",
    "        make_sets: If `True`, creates a set of unique values for each column.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "\n",
    "    def split_multiples(df: pd.DataFrame, col: str) -> None:\n",
    "        \"\"\"\n",
    "        Splits the values in a column by `,` and stores them in a new column, as a list.\n",
    "\n",
    "        Parameters:\n",
    "            df: The DataFrame to process.\n",
    "            col: The column to split.\n",
    "        \n",
    "        Returns:\n",
    "            None: The function modifies the DataFrame in place.\n",
    "        \"\"\"\n",
    "\n",
    "        df[col + 's'] = \\\n",
    "            df[col].apply(\n",
    "                lambda x: [val.strip() for val in x.split(',')] \n",
    "                    if pd.notnull(x) \n",
    "                    else None)\n",
    "        \n",
    "    def trim_name_urls(df: pd.DataFrame, col: str) -> None:\n",
    "        \"\"\"\n",
    "        Trims name URLs to just the important part.\n",
    "        This is used for director and star names.\n",
    "        \n",
    "        i.e. `'/name/nm0000001/'` becomes `'nm0000001'`\n",
    "        \n",
    "        Parameters:\n",
    "            df: The DataFrame to process.\n",
    "            col: The column to trim.\n",
    "        \n",
    "        Returns:\n",
    "            None: The function modifies the DataFrame in place.\n",
    "        \"\"\"\n",
    "\n",
    "        df[col] = df[col].apply(\n",
    "            lambda l: [x.split('/')[-2].strip() for x in l]\n",
    "                if isinstance(l, list) and len(l) > 0\n",
    "                else l)\n",
    "\n",
    "    if make_sets:\n",
    "        def track_uniques(df: pd.DataFrame, col: str, unique_set: set) -> None:\n",
    "            \n",
    "            \"\"\"\n",
    "            Tracks unique values in a column and stores them in a set.\n",
    "\n",
    "            Parameters:\n",
    "                df: The DataFrame to process.\n",
    "                col: The column to track unique values from.\n",
    "                unique_set: A set to store unique values.\n",
    "            \n",
    "            Returns:\n",
    "                None: The function modifies the set in place.\n",
    "            \"\"\"\n",
    "\n",
    "            for items in df[col + 's'].dropna():\n",
    "                # Add each item to the set\n",
    "                for item in items:\n",
    "                    unique_set.add(item)\n",
    "\n",
    "    ##########\n",
    "\n",
    "    for col in splits:\n",
    "        col_s = col + 's'\n",
    "        try:\n",
    "            # Split the column values by ',' and store in a new column\n",
    "            split_multiples(df, col)\n",
    "\n",
    "            # Trim name URLs for director and star names if applicable\n",
    "            if col_s in ['director_ids', 'star_ids']:\n",
    "                trim_name_urls(df, col_s)\n",
    "\n",
    "            if make_sets:\n",
    "                # Track unique values for each column\n",
    "                globals()[col_s] = set()\n",
    "                track_uniques(df, col, globals()[col_s])\n",
    "\n",
    "            df.drop(columns=[col], inplace=True) # Drop the original column to save space\n",
    "        except KeyError:\n",
    "            # Handle the case where the column might not exist in the DataFrame (i.e. this function has already been performed)\n",
    "            print(f\"Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "            if make_sets:\n",
    "                # Initialize an empty set to avoid errors later on\n",
    "                if col_s not in globals():\n",
    "                    globals()[col_s] = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df: pd.DataFrame, drops: Iterable = None, make_sets: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Performs all clean-up / preprocessing steps on the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df: The DataFrame to process.\n",
    "        drops: List of columns to drop from the DataFrame.\n",
    "        make_sets: If `True`, creates a set of unique values for each column.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "    \n",
    "    df.dropna(inplace=True, how='all') # Drop rows where all elements are None\n",
    "    try:\n",
    "        df.drop(columns=drops, inplace=True) # Drop specified columns\n",
    "    except:\n",
    "        # Handle the case where the columns might not exist in the DataFrame\n",
    "        print(f\"Columns {drops} not found in DataFrame.\\nHas preprocessing already been performed?\")\n",
    "        return\n",
    "\n",
    "    # NOTE: splits is a list of columns to split by ','.\n",
    "        # 'director' and 'star' columns are likely not useful,\n",
    "        # as they are just text (meaningless to a model, likely),\n",
    "        # so if they are included in drops, they will be ignored here.\n",
    "    splits = {\n",
    "        'genre',\n",
    "        'director',\n",
    "        'director_id',\n",
    "        'star',\n",
    "        'star_id',\n",
    "    } - drops\n",
    "\n",
    "    clean_and_split_columns(df, splits, make_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = {'description', 'director', 'star'}\n",
    "for category in categories:\n",
    "    # Prepare each category DataFrame\n",
    "    prepare(globals()[category], drops=drops, make_sets=True)\n",
    "\n",
    "del category\n",
    "del drops\n",
    "\n",
    "# NOTE: now, each category's DataFrame has:\n",
    "# - Empty rows removed,\n",
    "# - useless columns dropped,\n",
    "# - list-like columns split into lists and the original columns removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: testing\n",
    "\n",
    "# type(globals()['action']['genres'][0])\n",
    "# print(globals()['genres'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
