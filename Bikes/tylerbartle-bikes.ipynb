{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA0HPVmIBT4C"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from 'c:\\Program Files\\Python310\\lib\\site-packages\\typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import callbacks, optimizers, Sequential\n",
    "from keras.layers import Dense, Dropout, Input # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
    "df = pd.read_csv('bikes.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(df: pd.DataFrame) -> pd.DataFrame:  \n",
    "    # Extract year, month, and day into separate columns and convert to numbers (rather than strings)\n",
    "    df[['month', 'day', 'year']] = df['dteday'].str.extract(r'(\\d*)/(\\d*)/(\\d*)')\n",
    "    df['month'] = pd.to_numeric(df['month'])\n",
    "    df['day'] = pd.to_numeric(df['day'])\n",
    "    df['year'] = pd.to_numeric(df['year'])\n",
    "    # Don't need the garbage format date column, throw it away\n",
    "    df.drop(columns=['dteday'], errors='ignore', inplace=True)\n",
    "    return df\n",
    "\n",
    "# df = split_date(df)\n",
    "# df.head(220) # confirm that one- and two-digit months and days are handled correctly\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # One-hot encode the categorical variables\n",
    "    df['weathersit'] = df['weathersit'].map({1: 'none', 2: 'light', 3: 'moderate', 4: 'heavy'})\n",
    "    df['season'] = df['season'].map({1: 'winter', 2: 'spring', 3: 'summer', 4: 'fall'})\n",
    "    df = pd.get_dummies(df, columns=['season', 'weathersit'], prefix=['','weather'], prefix_sep=['','_'], dtype=int)\n",
    "    return df\n",
    "\n",
    "# df = convert_categorical(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bikes.csv')\n",
    "df = split_date(df)\n",
    "df = convert_categorical(df)\n",
    "# df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daylight Savings Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was exploring the data, I found out that the hour of 2 a.m. has 13 less entries than all of the other ones, which was weird to me. Upon further examination, the \"missing\" 2 a.m. entry occurred in March of each year, which led me to believe it might be because of Daylight Savings. Turns out, that's entirely correct: March 13, 2011 was Daylight Savings, and that day is missing an entry for 2 a.m.\n",
    "\n",
    "This does, however, raise the question of why there isn't a *duplicate* 2 a.m. entry each November..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hr'].value_counts() # 2 a.m. has 13 less entries than the other hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_year = df['year'].max()\n",
    "# min_year = df['year'].min()\n",
    "# max_month = df[df['year'] == max_year]['month'].max()\n",
    "# min_month = df[df['year'] == min_year]['month'].min()\n",
    "# num_months = (max_year - min_year) * 12 + max_month - min_month + 1\n",
    "\n",
    "one_day_per_month = df[(df['day'] == 1) & (df['hr'] == 0.0)][['month', 'year']].copy()\n",
    "num_months = one_day_per_month.shape[0]\n",
    "num_years = one_day_per_month['year'].nunique()\n",
    "od = one_day_per_month\n",
    "num_29 = od[(od['month'] != 2) | ((od['month'] == 2) & (od['year'] % 4 == 0))].shape[0]\n",
    "num_30 = od[(od['month'] != 2)].shape[0]\n",
    "num_31 = od[(od['month'] != 2) & (od['month'] != 4) & (od['month'] != 6) & (od['month'] != 9) & (od['month'] != 11)].shape[0]\n",
    "\n",
    "print(f'{num_months} total months in the dataset.') # 154\n",
    "print(f'{num_29} have at least 29 days.') # 144\n",
    "print(f'{num_30} have at least 30 days.') # 141\n",
    "print(f'{num_31} have 31 days.') # 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_1am = df[df['hr'] == 1]\n",
    "# just_1am['day'].value_counts()\n",
    "# This has the expected number of entries.\n",
    "just_1am_filtered = just_1am[(just_1am['day'] == 8) | (just_1am['day'] == 9) | (just_1am['day'] == 10) | (just_1am['day'] == 11) | (just_1am['day'] == 12) | (just_1am['day'] == 13) | (just_1am['day'] == 14)]\n",
    "just_1am_filtered = just_1am_filtered[(just_1am_filtered['month'] == 3)]\n",
    "just_1am_filtered['day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_2am = df[df['hr'] == 2]\n",
    "# just_2am['day'].value_counts()\n",
    "just_2am_filtered = just_2am[(just_2am['day'] == 8) | (just_2am['day'] == 9) | (just_2am['day'] == 10) | (just_2am['day'] == 11) | (just_2am['day'] == 12) | (just_2am['day'] == 13) | (just_2am['day'] == 14)]\n",
    "just_2am_filtered = just_2am_filtered[(just_2am_filtered['month'] == 3)]\n",
    "just_2am_filtered['day'].value_counts()\n",
    "# just_2am_filtered[['month', 'day', 'year']].to_csv('just_2am_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_2am = just_2am[(just_2am['day'] == 8) | (just_2am['day'] == 9) | (just_2am['day'] == 10) | (just_2am['day'] == 11) | (just_2am['day'] == 12) | (just_2am['day'] == 13) | (just_2am['day'] == 14)]\n",
    "dmy_2am = dmy_2am[(dmy_2am['month'] == 3)]\n",
    "dmy_2am = dmy_2am[['day', 'year']]\n",
    "# dmy_2am.head()\n",
    "\n",
    "daylight_savings_days = {}\n",
    "for year in range(df['year'].min(), df['year'].max() + 1):\n",
    "    for day in range(8, 15):\n",
    "        if day not in dmy_2am[dmy_2am['year'] == year].to_numpy():\n",
    "            daylight_savings_days[year] = day\n",
    "\n",
    "for year, day in daylight_savings_days.items():\n",
    "    print(f'{year}: March {day}')\n",
    "\n",
    "# These are all correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('bikes.csv')\n",
    "bikes = split_date(bikes)\n",
    "bikes = convert_categorical(bikes)\n",
    "# bikes.info()\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bikes.drop(columns=['casual', 'registered'])\n",
    "y = bikes[['casual', 'registered']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StiU5QcPPxqQ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam()\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.config.list_logical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = callbacks.EarlyStopping(patience=30)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2000, validation_split=.35, batch_size=20, callbacks=[early_stop], shuffle=False)\n",
    "# history = model.fit(train_features, train_labels, epochs=2000, verbose=0, validation_split = .2, batch_size=tester2,\n",
    "#                     callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pd.read_csv('bikes_holdout_mini.csv')\n",
    "mini = split_date(mini)\n",
    "mini = convert_categorical(mini)\n",
    "# mini.info()\n",
    "mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = mini.reindex(columns = X.columns, fill_value=0)\n",
    "mini_X = scaler.transform(mini)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/byui-cse/cse450-course/blob/master/notebooks/starter_bikes.ipynb",
     "timestamp": 1740162610799
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
