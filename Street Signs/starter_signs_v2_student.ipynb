{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import cv2\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "from tensorflow.data import Dataset # type: ignore\n",
        "from tensorflow.keras import layers, Sequential # type: ignore\n",
        "from tensorflow.keras.applications import EfficientNetB3 # type: ignore\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D # type: ignore\n",
        "from tensorflow.keras.models import Model # type: ignore\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('cpu_compiler', '/usr/lib/llvm-18/bin/clang'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n",
            "tensorflow version 2.18.0\n",
            "Num GPUs Available: 1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1741387477.137852  328417 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "print(tf.sysconfig.get_build_info())\n",
        "print(f'tensorflow version {tf.__version__}')\n",
        "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.config.list_logical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA0HPVmIBT4C"
      },
      "outputs": [],
      "source": [
        "# !echo \"Downloading files...\"\n",
        "# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip\n",
        "# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip\n",
        "# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/holdout.zip\n",
        "# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/mini_holdout.zip\n",
        "# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/mini_holdout_answers.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upscaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resized 52040 images and saved them to upscaled\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "input_folder = \"original\"\n",
        "output_folder = \"upscaled\"\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create output directory if not exists\n",
        "\n",
        "# Set target resolution\n",
        "target_size = (300, 300)  # Change this as needed (e.g., 300x300 for B3)\n",
        "\n",
        "# Get all image files\n",
        "image_files = []\n",
        "image_files.extend(glob(os.path.join(input_folder, \"**\", \"*.jpg\"), recursive=True))\n",
        "\n",
        "# Process images\n",
        "for img_path in image_files:\n",
        "    # Determine relative path inside original folder\n",
        "    relative_path = os.path.relpath(img_path, input_folder)\n",
        "\n",
        "    # Create corresponding output path\n",
        "    output_path = os.path.join(output_folder, relative_path)\n",
        "\n",
        "    # Ensure the target directory exists\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    # Load and resize image\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"Skipping corrupted file: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "    # Save the resized image\n",
        "    cv2.imwrite(output_path, img_resized)\n",
        "\n",
        "print(f\"Resized {len(image_files)} images and saved them to {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths\n",
        "dataset_path = \"upscaled/training\"\n",
        "batch_size = 32\n",
        "img_size = (100, 100)  # Change if using a different EfficientNet variant\n",
        "\n",
        "# Get class names from directory structure\n",
        "# class_names = sorted(os.listdir(dataset_path))\n",
        "class_names = ['Speed_20', 'Speed_30', 'Speed_50', 'Speed_60', 'Speed_70',\n",
        "               'Speed_80','Speed_Limit_Ends', 'Speed_100', 'Speed_120', 'Overtaking_Prohibited',\n",
        "               'Overtakeing_Prohibited_Trucks', 'Crossroad_Ahead', 'Priority_Road_Ahead', 'Yield', 'STOP',\n",
        "               'Entry_Forbidden', 'Trucks_Forbidden', 'No_Entry(one-way traffic)', 'Cars_Prohibited(!)', 'Left_Curve_Ahead',\n",
        "               'Right_Curve_Ahead', 'Bends_Left_Then_Right', 'Poor_Surface_Ahead', 'Slippery_Surface_Ahead', 'Road_Narrows_On_Right',\n",
        "               'Roadwork_Ahead', 'Traffic_Light_Ahead', 'Warning_Pedestrians', 'Warning_Children', 'Warning_Bikes',\n",
        "               'Uncontrolled_Crossroad', 'Deer_Crossing', 'End_Previous_Limitation', 'Turning_Right_Compulsory', 'Turning_Left_Compulsory',\n",
        "               'Ahead_Only', 'Straight_Or_Right_Mandatory', 'Straight_Or_Left_Mandatory', 'Passing_Right_Compulsory', 'Passing_Left_Compulsory',\n",
        "               'Roundabout', 'End_Overtaking_Prohibition', 'End_Overtaking_Prohibition_Trucks']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Get all image file paths\n",
        "image_paths = tf.io.gfile.glob(os.path.join(dataset_path, \"*\", \"*.jpg\"))  # Adjust extension if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path):\n",
        "    # Read image file\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Change to decode_png if needed\n",
        "    image = tf.image.resize(image, img_size)  # Resize to match EfficientNet input\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "def get_label(image_path):\n",
        "    parts = tf.strings.split(image_path, os.sep)  # Split path by \"/\"\n",
        "    label_str = parts[-2]  # Folder name is the class label\n",
        "    label = tf.argmax(label_str == class_names)  # Convert to integer label\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert file paths into a tf.data.Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "# Apply preprocessing and labeling functions\n",
        "dataset = dataset.map(lambda x: (load_and_preprocess_image(x), get_label(x)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Shuffle and split dataset\n",
        "dataset = dataset.shuffle(buffer_size=len(image_paths), seed=42)\n",
        "\n",
        "train_size = int(0.8 * len(image_paths))  # 80% for training\n",
        "train_ds = dataset.take(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = dataset.skip(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rF7USssdNuDh"
      },
      "outputs": [],
      "source": [
        "data_augmentation = Sequential([\n",
        "    layers.Rescaling(1./255),  # Normalize to [0,1]\n",
        "    layers.RandomFlip(\"horizontal\"),  # Random horizontal flips\n",
        "    layers.RandomRotation(0.1),  # Rotate by up to 10%\n",
        "    layers.RandomZoom(0.2),  # Random zoom\n",
        "    layers.RandomContrast(0.2),  # Adjust contrast slightly\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load EfficientNet with pre-trained ImageNet weights\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
        "base_model.trainable = False  # Freeze base model initially\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)  # Prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output_layer = Dense(num_classes, activation='softmax')(x)  # Multi-class classification\n",
        "\n",
        "# Define model\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',  # Integer labels\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,  # Start small; increase if needed\n",
        "    validation_data=val_ds\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post-Gen Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnGBwGVZPyyh"
      },
      "outputs": [],
      "source": [
        "# View 9 images and their class labels\n",
        "plt.figure(figsize=(10, 10))\n",
        "images, labels = next(train_generator)  # Assuming train_generator is a generator\n",
        "batch_size = images.shape[0]\n",
        "\n",
        "for i in range(min(9, batch_size)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow((images[i] * 255).astype(\"uint8\"))\n",
        "    plt.title(int(labels[i]))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "outputs": [],
      "source": [
        "# Build a model..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDc0xuoZs3DK"
      },
      "source": [
        "## Testing the model\n",
        "Once you have built and trained your model, the next step is to run the mini holdout images through it and see how well your model does at making predictions for images it has never seen before.\n",
        "\n",
        "Since loading these images and formatting them for the model can be tricky, you may find the following code useful. This code only uses your model to predict the class label for a given image. You'll still need to compare those predictions to the \"ground truth\" class labels in `mini_holdout_answers.csv` to evaluate how well the model does.\n",
        "\n",
        "Previously, you were given a file that would check your results. This time you're given the answers to the first mini holdout dataset. You'll need to compare those predictions against the \"ground truth\" class labels in `mini_holdout_answers.csv` to evaluate how well the model does.\n",
        "\n",
        "Make sure to use the insights gained from the mini hold out dataset in your executive summary.\n",
        "\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['mini_holdout'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodPABZ-Yz-6"
      },
      "source": [
        "##Mini Hold out Dataset\n",
        "\n",
        "\n",
        "Once you feel confident, you will need to predict for the full holdout dataset using the following code, and submit your csv file:\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['holdout'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "starter_signs_v2_student.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.12 (tf-env)",
      "language": "python",
      "name": "tf-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
